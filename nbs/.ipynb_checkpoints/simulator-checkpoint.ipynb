{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51010347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T21:19:03.101575Z",
     "start_time": "2022-09-27T21:19:02.923720Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "from scipy.optimize import minimize, Bounds, LinearConstraint, NonlinearConstraint, shgo, dual_annealing, \\\n",
    "    differential_evolution, basinhopping\n",
    "from functools import partial\n",
    "from helper import *\n",
    "\n",
    "def recommendation_media(data, current_volume, growth_ambition_perc):\n",
    "    data = convert_df(data)\n",
    "\n",
    "    data['current_effectiveness_per_metric'] = data['current_effectiveness_per_unit'] / data['one_unit_metric_quantity']\n",
    "    data['input_cost_per_metric'] = data['input_cost_per_unit'] / data['one_unit_metric_quantity']\n",
    "\n",
    "    # separating the dataframe , will be used for aggregating afterwards\n",
    "    df_only = data[data['genre_platform'] != 'Total'].reset_index(drop=True)\n",
    "    df_total = data[data['genre_platform'] == 'Total'].reset_index(drop=True)\n",
    "\n",
    "    #seperating TV and digital data into two seperate dataframes(total_tv,total_digital)\n",
    "    total_tv = df_total.query(\"media_type = = 'TV'\")\n",
    "    total_digital = df_total.query(\"media_type == 'Digital'\")\n",
    "\n",
    "    growth_ambition_volume = current_volume * growth_ambition_perc\n",
    "    current_volume_contribution = df_total['current_volume'].sum()\n",
    "    matrix_3_min_cons = growth_ambition_volume + current_volume_contribution\n",
    "\n",
    "    # This is one of the main feature for the algorithm\n",
    "    def bounds_col(value, media_type, min_=0, max_=0, total_tv_spends=0, total_digital_spends=0):\n",
    "        '''\n",
    "        This function is used for making lower and upper bounds for the minimize function.\n",
    "        it takes in 7 arguments - \n",
    "        '''\n",
    "\n",
    "        if min_ != 0:\n",
    "            # if media_type == 'TV': return 0.05 * value  # 20% of current_metric_value\n",
    "            if media_type == 'TV': return (0.05 * total_tv_spends) / value  # 5% of input_total_tv_spends\n",
    "            if media_type == 'Digital': return (0.05 * total_digital_spends) / value  # 5% of input_total_digital_spends\n",
    "\n",
    "        if max_ != 0:\n",
    "            if media_type == 'TV': return (0.3 * total_tv_spends) / value  # 30% of input_total_tv_spends\n",
    "            if media_type == 'Digital': return (0.6 * total_digital_spends) / value # 60% of input_total_digital_spends\n",
    "\n",
    "    def volume_growth(value_to_optimize, data=df_only):\n",
    "        data['recommendation_metric_value'] = value_to_optimize\n",
    "        cal_values = list(map(lambda rv, mi, ma: True if mi <= rv <= ma else False, data['recommendation_metric_value'],\n",
    "                              data['lower_bounds'], data['upper_bounds']))\n",
    "        if all(cal_values):\n",
    "            total_val = -(data['current_effectiveness_per_metric'] * data['recommendation_metric_value']).sum()\n",
    "        else:\n",
    "            total_val = 1e9\n",
    "        return total_val\n",
    "\n",
    "    # getting lower and upper bounds\n",
    "    df_only['lower_bounds'] = tuple(\n",
    "        map(lambda x, y: bounds_col(x, y, min_=1, total_tv_spends=total_tv['input_spends'].values[0],\n",
    "                                    total_digital_spends=total_digital['input_spends'].values[0]),\n",
    "            df_only['input_cost_per_metric'], df_only['media_type']))\n",
    "\n",
    "    df_only['upper_bounds'] = tuple(\n",
    "        map(lambda x, y: bounds_col(x, y, max_=1, total_tv_spends=total_tv['input_spends'].values[0],\n",
    "                                    total_digital_spends=total_digital['input_spends'].values[0]),\n",
    "            df_only['input_cost_per_metric'], df_only['media_type']))\n",
    "    \n",
    "    # making constraint matrix\n",
    "    # df_only['matrix_row_1_tv'] = df_only['media_type'].apply(lambda x: 1 if x == 'TV' else 0)\n",
    "    df_only['matrix_row_1_tv'] = df_only['media_type'].apply(lambda x: np.nan if x == 'TV' else 0).fillna(\n",
    "        df_only['input_cost_per_metric'])\n",
    "    df_only['matrix_row_2_digital'] = df_only['media_type'].apply(lambda x: np.nan if x == 'Digital' else 0).fillna(\n",
    "        df_only['input_cost_per_metric'])\n",
    "\n",
    "    df_only['matrix_row_3_vg'] = df_only['current_effectiveness_per_metric'].copy()\n",
    "\n",
    "    # start_values are the game.\n",
    "    # This is one of the key feature for the algorithm\n",
    "    df_only['start_values'] = 0\n",
    "\n",
    "    # bounds and constraint\n",
    "    bounds = Bounds(lb=df_only['lower_bounds'], ub=df_only['upper_bounds'], keep_feasible=True)\n",
    "\n",
    "    #Constructing constraints ,When there is only one media_type i.e, Digital\n",
    "    if (len(data['media_type'].unique()) == 1):\n",
    "        if (data['media_type'].unique() == 'Digital'):\n",
    "            # below cons_ for whenever there is only digital data\n",
    "            cons_ = [LinearConstraint(A=df_only[['matrix_row_2_digital']].T.values.tolist(),\n",
    "                                      lb=(total_digital['input_spends'].values[0]),\n",
    "                                      ub=(total_digital['input_spends'].values[0]),\n",
    "                                      keep_feasible=True)]\n",
    "    else:\n",
    "        # below cons_ for generic data\n",
    "        cons_ = [LinearConstraint(A=df_only[['matrix_row_1_tv', 'matrix_row_2_digital']].T.values.tolist(),\n",
    "                                  lb=([total_tv['input_spends'].values[0], total_digital['input_spends'].values[0]]),\n",
    "                                  ub=([total_tv['input_spends'].values[0], total_digital['input_spends'].values[0]]),\n",
    "                                  keep_feasible=True)]\n",
    "\n",
    "    ineqcons_ = LinearConstraint(\n",
    "        A=df_only[['matrix_row_3_vg']].T.values.tolist(),\n",
    "        lb=([matrix_3_min_cons]),\n",
    "        ub=([np.inf]),\n",
    "        keep_feasible=False)\n",
    "\n",
    "    cons_.append(ineqcons_)\n",
    "\n",
    "    '''minimize is the scipy optimize func where it takes the start ,bounds and constraint values\n",
    "      optimize_output is an o/p from the scipy algo'''\n",
    "#     optimize_output = minimize(volume_growth, x0=df_only['start_values'], args=df_only,\n",
    "#                                bounds=bounds, constraints=cons_,\n",
    "#                                hess=lambda x, data: np.zeros((x.shape[0], x.shape[0])))\n",
    "\n",
    "#     optimize_output = minimize(volume_growth, x0=df_only['start_values'], args=df_only,\n",
    "#                            bounds=bounds,\n",
    "#                            hess=lambda x, data: np.zeros((x.shape[0], x.shape[0])))\n",
    "    \n",
    "    ###########################################\n",
    "    cipm = df_only[\"current_effectiveness_per_metric\"].values\n",
    "    \n",
    "    optimized_variable = cp.Variable(df_only.shape[0], \"recommendation_metric_value\")\n",
    "    \n",
    "    lower_bound = df_only['lower_bounds'].values\n",
    "    upper_bound = df_only[\"upper_bounds\"].values\n",
    "    \n",
    "    func = (cipm @ optimized_variable)\n",
    "    \n",
    "    obj = cp.Maximize(func)\n",
    "    \n",
    "    const1 = [optimized_variable >= lower_bound]\n",
    "    const2 = [optimized_variable <= upper_bound]\n",
    "    \n",
    "    const = const1+const2\n",
    "    prob = cp.Problem(obj, constraints=const)\n",
    "    \n",
    "    prob.solve(solver=cp.SCIPY, verbose = True)\n",
    "    \n",
    "    print(\"optimality status\", prob.status)\n",
    "    print(\"optimal value\", prob.value) \n",
    "    \n",
    "    df_only[\"recommendation_metric_value\"] = optimized_variable.value\n",
    "    ############################################\n",
    "    \n",
    "    \n",
    "\n",
    "    # recommended value\n",
    "    df_total = brand_level(df_only, df_total, 'recommendation_metric_value')\n",
    "\n",
    "    # recommended spends\n",
    "    df_only['recommendation_spends'] = df_only['recommendation_metric_value'] * df_only['input_cost_per_metric']\n",
    "    df_total = brand_level(df_only, df_total, 'recommendation_spends')\n",
    "\n",
    "    # recommended volume\n",
    "    df_only['recommendation_volume'] = df_only['recommendation_metric_value'] * df_only[\n",
    "        'current_effectiveness_per_metric']\n",
    "    df_total = brand_level(df_only, df_total, 'recommendation_volume')\n",
    "\n",
    "    # revenue \n",
    "    df_only['recommendation_revenue'] = (df_only['recommendation_volume'] * df_only['current_price_per_volume'])\n",
    "    df_total = brand_level(df_only, df_total, 'recommendation_revenue')\n",
    "\n",
    "    # roi\n",
    "    df_only['recommendation_roi'] = df_only['recommendation_revenue'] / df_only['recommendation_spends']\n",
    "\n",
    "    # brand level roi\n",
    "    df_total['recommendation_roi'] = df_total['recommendation_revenue'] / df_total['recommendation_spends']\n",
    "\n",
    "    # merging the frames and returning\n",
    "    recommendation_frame = pd.concat([df_only, df_total], ignore_index=True)\n",
    "    recommendation_frame[['scenario_spends', 'scenario_metric_value']] = np.nan\n",
    "    debug_columns = ['lower_bounds', 'upper_bounds', 'matrix_row_1_tv', 'matrix_row_2_digital', 'matrix_row_3_vg', 'start_values']\n",
    "    recommendation_frame = recommendation_frame.drop(columns=debug_columns)\n",
    "    return recommendation_frame.fillna(-1), optimize_output.success\n",
    "    \n",
    "\n",
    "''' Below func will excute if algo didn't converge at the user specified growth_amb_perc. \n",
    "    It will find the appropriate/max growth_amb_perc ,ROI and spends where algo converges it better. \n",
    "'''\n",
    "def binary_search(df_constraints_media, current_volume, array, low, high):\n",
    "    if high >= low:\n",
    "        mid = low + (high - low) // 2\n",
    "        recommendation_media_df, media_convergence_flag = recommendation_media(df_constraints_media, current_volume,\n",
    "                                                                               array[mid])\n",
    "        if media_convergence_flag:\n",
    "            return array[mid]\n",
    "        else:\n",
    "            return binary_search(df_constraints_media, current_volume, array, low, mid + 1)\n",
    "    return -1\n",
    "\n",
    "'''Below snippet will recommended us where to invest out our remaining input spends on  different paramerts'''\n",
    "\n",
    "def recommendation_execution(df_dist, remainder_volume_growth):\n",
    "    df_dist = convert_df(df_dist)\n",
    "\n",
    "    #Remaining input spends will be chop into the below list of variables\n",
    "    current_val = ['current_price_per_volume', 'current_distribution', 'current_trade']\n",
    "    df_dist_analysis = data_manipulation_execution(df_dist, current_val, inp_col_name='current_val')\n",
    "\n",
    "    #calculations for three variables\n",
    "    def volume_constraint(data, x):\n",
    "        data['Recommended_val'] = x\n",
    "        vg = volume_growth_execution(data, return_sum=True)\n",
    "        return vg\n",
    "\n",
    "    def cost_of_distribution(data):\n",
    "        cost = 0.01 * (data['Recommended_val'] - data['current_val'])\n",
    "        return sum(cost)\n",
    "\n",
    "    def cost_of_price(data):\n",
    "        vg = volume_growth_execution(data)\n",
    "        cost = vg * (data['Recommended_val'] - data['current_val'])\n",
    "        return sum(cost)\n",
    "\n",
    "    def cost_of_trade(data):\n",
    "        vg = volume_growth_execution(data)\n",
    "        cost = vg * (data['Recommended_val'] - data['current_val']) * data['current_price_per_volume']\n",
    "        return sum(cost)\n",
    "\n",
    "    def cost(values_to_optimize, data):\n",
    "        data['Recommended_val'] = values_to_optimize\n",
    "        cal_values = list(\n",
    "            map(lambda rv, mi, ma: True if mi <= rv <= ma else False, data['Recommended_val'], data['lower_bounds'],\n",
    "                data['upper_bounds']))\n",
    "\n",
    "        if all(cal_values):\n",
    "\n",
    "            p = cost_of_price(data[data['lever'] == 'price'])\n",
    "            d = cost_of_distribution(data[data['lever'] == 'distribution'])\n",
    "            t = cost_of_trade(data[data['lever'] == 'trade'])\n",
    "\n",
    "            total_val = p + d + t\n",
    "            return total_val\n",
    "\n",
    "        else:\n",
    "            total_val = 1e9\n",
    "\n",
    "        return total_val\n",
    "\n",
    "    # Bounds\n",
    "    margin = 0.1\n",
    "    df_dist_analysis['lower_bounds'] = df_dist_analysis['current_val'] * (1 - margin)\n",
    "    df_dist_analysis['upper_bounds'] = df_dist_analysis['current_val'] * (1 + margin)\n",
    "    df_dist_analysis['start_values'] = 0\n",
    "\n",
    "    df_dist_analysis.loc[df_dist_analysis['lever'] == 'price', 'upper_bounds'] = df_dist_analysis['current_val']\n",
    "    df_dist_analysis.loc[df_dist_analysis['lever'] == 'distribution', 'lower_bounds'] = df_dist_analysis['current_val']\n",
    "\n",
    "    # Changing trade bounds as per user input\n",
    "    cc = df_dist[['id', 'channel', 'pack_name', 'current_trade', 'input_trade']].dropna().reset_index(drop=True)\n",
    "    cc['lower_bounds'] = cc[['current_trade', 'input_trade']].dropna().min(axis=1)\n",
    "    cc['upper_bounds'] = cc[['current_trade', 'input_trade']].dropna().max(axis=1)\n",
    "\n",
    "    for i in cc.itertuples():\n",
    "        df_dist_analysis.loc[(df_dist_analysis['id'] == i[1]) & (df_dist_analysis['channel'] == i[2]) & (df_dist_analysis['lever'] == 'trade'), 'lower_bounds'] = \\\n",
    "            i[-2]\n",
    "        df_dist_analysis.loc[(df_dist_analysis['id'] == i[1]) & (df_dist_analysis['channel'] == i[2]) & (df_dist_analysis['lever'] == 'trade'), 'upper_bounds'] = \\\n",
    "            i[-1]\n",
    "\n",
    "    # df_dist_analysis = df_dist_analysis.query(\"lower_bounds < upper_bounds\")\n",
    "    bounds = Bounds(lb=df_dist_analysis['lower_bounds'], ub=df_dist_analysis['upper_bounds'], keep_feasible=False)\n",
    "\n",
    "    # constraints\n",
    "    nl_constraints = NonlinearConstraint(partial(volume_constraint, df_dist_analysis.copy(deep=True)),\n",
    "                                         lb=remainder_volume_growth,\n",
    "                                         ub=np.inf,\n",
    "                                         keep_feasible=False)\n",
    "    '''minimize is the scipy optimize func where it takes the start ,bounds and constraint values\n",
    "      result is an o/p from the scipy algo'''\n",
    "\n",
    "    result = minimize(cost, x0=df_dist_analysis['start_values'], args=df_dist_analysis,\n",
    "                      bounds=bounds, constraints=[nl_constraints],\n",
    "                      hess=lambda x, data: np.zeros((x.shape[0], x.shape[0])),\n",
    "                      method='trust-constr',\n",
    "                      options={'maxiter': 1000, 'verbose': 1, 'factorization_method': 'SVDFactorization'})\n",
    "\n",
    "    # getting recommendation cols\n",
    "    new_names_r = ['recommendation_' + i.replace('current_', '') for i in current_val]\n",
    "    df_dist_analysis[new_names_r] = tuple(map(lambda lv, val: out(lv, val),\n",
    "                                              df_dist_analysis['lever'], df_dist_analysis['Recommended_val']))\n",
    "    # volume growth\n",
    "    df_dist_analysis['volume_growth'] = volume_growth_execution(df_dist_analysis)\n",
    "    new_names_v = [i + '_incremental_volume' for i in new_names_r]\n",
    "    df_dist_analysis[new_names_v] = tuple(map(lambda lv, val: out(lv, val),\n",
    "                                              df_dist_analysis['lever'], df_dist_analysis['volume_growth']))\n",
    "    df_dist_analysis.drop(columns=['Recommended_val', ], inplace=True)\n",
    "\n",
    "    final_exec = df_dist.copy()\n",
    "    for r, v in zip(new_names_r, new_names_v): final_exec = pd.merge(final_exec, df_dist_analysis[['id', r, v]].dropna(\n",
    "        subset=[r, ]), on=['id', ], how='left')\n",
    "\n",
    "    final_exec = total_execution(final_exec, new_names_v, try_=0)\n",
    "    new_names_s = ['scenario_' + i.replace('current_', '') for i in current_val]\n",
    "    final_exec[new_names_s] = np.nan\n",
    "    return final_exec.fillna(-1), result.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18eb208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
